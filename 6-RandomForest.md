# RandomForest

## Random Forest Classifier And Regresor
1. Ensemble Techniques(Boosting And Bagging)
2. Working of Random Forest Classifier
3. Working of Random Forest Regresor
4. Hyperparameter Tuning(Grid Search And RandomSearch)

## Important properties of Random Forest Classifiers

1. Decision Tree - Low Bias and High Variance
2. Ensemble Baggin(Random Forest Classifier) -- Low Bias and Low Variance.

## Basic assumption?
There is no such assumptions.

## Advantages (Random Forest)
1. Doesn't overfit
2. Favourite algorithm for Kaggle Competion.
3. Less Parameter Tuning required.
4. Decision Tree can handle both continous and categorical variables.
5. No feature scaling required: No feature scaling (standardization and normalization) required in case of Random Forest as it used (Decision Tree internally)
6. Suitable for any Kind of ML problems.

## Disadvantages 
- Biased with features having many categories.
- Biased in multiclass classification problems towards more frequent classes.


## Whether feature scaling is required?
No

## Impact of outliers?
Robust to outliers

## Types of problems it can solve
1. Classification
2. Regression

